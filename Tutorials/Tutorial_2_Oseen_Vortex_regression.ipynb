{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "070d2146",
   "metadata": {},
   "source": [
    "# SPICY Tutorial 2\n",
    "\n",
    "In this tutorial we use SPICY for the constrained regression of a solenoidal velocity field in 2D. We perform the regression in two ways: \n",
    "\n",
    "1. Free regression of two scalar fields, using one SPICY object per component. \n",
    "\n",
    "2. Penalized regression with one vector field, using one SPICY object with penalties on the div free condition.\n",
    "\n",
    "We start by importing the relevant packages and customizing the plots. For this, LaTeX needs to be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134e5b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline  \n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..' + os.sep + 'spicy_vki' + os.sep + 'spicy')\n",
    "from spicy_class import spicy\n",
    "\n",
    "# This is for plot customization\n",
    "fontsize = 12\n",
    "plt.rc('text', usetex=True)      \n",
    "plt.rc('font', family='serif')\n",
    "plt.rcParams['xtick.labelsize'] = fontsize\n",
    "plt.rcParams['ytick.labelsize'] = fontsize\n",
    "plt.rcParams['axes.labelsize'] = fontsize\n",
    "plt.rcParams['legend.fontsize'] = fontsize\n",
    "plt.rcParams['font.size'] = fontsize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8781fc6",
   "metadata": {},
   "source": [
    "#### Test Case Definition\n",
    "\n",
    "We consider the domain $(x,y) = [-0.5,0.5]\\times[-0.5,0.5]$ and the velocity field produced by an Oseen vortex.\n",
    "\n",
    "In terms of radial an tangential components respectively, this means $u_r = 0$ and $u_\\theta = \\Gamma/2 \\pi r \\left( 1- e ^{-r^2/c_\\theta}\\right)$.\n",
    "\n",
    "Here, $c_\\theta = r_c^2 / \\gamma$, with $r_c = 0.1$ the radial distance of maximum velocity, $\\gamma = 1.25643$ and $\\Gamma = 10$ the dimensionless circulation.\n",
    "\n",
    "We assume that the flow has been sampled over $n_p=1000$ scattered points and a random error with 0.4 maximum intensity is present in the measurement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7f0673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the random seed to ensure reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of particles\n",
    "n_p = 1000\n",
    "\n",
    "# Define the domain boundaries and flow properties\n",
    "x1_hat, x2_hat = -0.5, 0.5 # m, m\n",
    "y1_hat, y2_hat = -0.5, 0.5 # m, m\n",
    "rho = 1 # kg/m^3\n",
    "mu = 0 # Pa s\n",
    "\n",
    "# Generate the random points\n",
    "X = np.random.random(n_p)*(x2_hat - x1_hat) + x1_hat\n",
    "Y = np.random.random(n_p)*(y2_hat - y1_hat) + y1_hat\n",
    "\n",
    "# Compute the radius and angle in the 2D domain\n",
    "r = np.sqrt(X**2 + Y**2); theta = np.arctan2(Y, X)\n",
    "\n",
    "# Hyperparameters of the vortex\n",
    "Gamma = 10; r_c = 0.1; gamma = 1.256431; c_theta = r_c**2/gamma\n",
    "\n",
    "# Compute the velocity field\n",
    "u_theta = Gamma / (2*np.pi*r) * (1 - np.exp(-r**2 / (r_c**2 / gamma)))\n",
    "U = np.sin(theta) * u_theta\n",
    "V = -np.cos(theta) * u_theta \n",
    "\n",
    "# Add 0.4 max noise to it\n",
    "q = 0.4\n",
    "U_noise = U * (1 + q*np.random.uniform(-1, 1, size = U.shape))\n",
    "V_noise = V * (1 + q*np.random.uniform(-1, 1, size = V.shape))\n",
    "\n",
    "# Plot the sampled field: black arrows for the true fields, blu arrows for the noisy one\n",
    "plt.quiver(X,Y,U,V)\n",
    "plt.quiver(X,Y,U_noise,V_noise,color='blue')\n",
    "plt.gca().set_aspect('equal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e1a44c",
   "metadata": {},
   "source": [
    "## Approach 1: Unconstrained regression(s) of scalar fields\n",
    "\n",
    "We proceed with the approach one: one regression for each component and no constraints!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873d6798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use one regression for each component.\n",
    "SP_U = spicy([U_noise], [X,Y], basis='c4') # initialize object\n",
    "SP_U.clustering([4,10], Areas=[[],[]], r_mM=[0.1,1.2], eps_l=0.87) # cluster\n",
    "SP_U.scalar_constraints() #add no constraints!\n",
    "SP_U.plot_RBFs(l=0) # plot the result of the clustering\n",
    "\n",
    "SP_U.Assembly_Regression() # Assembly the linear system\n",
    "SP_U.Solve(K_cond=1e8) # Solve the regression with regularization active when condition number exceed 1e8)\n",
    "U_c = SP_U.Get_Sol([X,Y]) # get solution on (X,Y)\n",
    "# Evaluate the error wrt to the noise free data\n",
    "error = np.linalg.norm(U_c - U) / np.linalg.norm(U)\n",
    "print('l2 relative error in u component: {0:.3f}%'.format(error*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe826b37",
   "metadata": {},
   "source": [
    "We now repeat the same for the regression of the other velocty component. Note that we do not want to re-do the clustering so we just clone the SPICY object, replace the target data and continue from there onward. Then, we plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2513bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_V=SP_U # clone the SPICY object\n",
    "SP_V.u = V_noise # Change only the target data (for scalar, this is u) \n",
    "SP_V.Assembly_Regression() # Assembly the linear system\n",
    "SP_V.Solve(K_cond=1e8) # Solve the regression with regularization active when condition number exceed 1e8)\n",
    "V_c = SP_V.Get_Sol([X,Y]) # get solution on (X,Y)\n",
    "# Evaluate the error wrt to the noise free data\n",
    "error = np.linalg.norm(V_c - V) / np.linalg.norm(V)\n",
    "print('l2 relative error in v component: {0:.3f}%'.format(error*100))\n",
    "\n",
    "# Then plot the results:\n",
    "plt.figure()\n",
    "plt.quiver(X,Y,U,V)\n",
    "plt.quiver(X,Y,U_noise,V_noise,color='blue')\n",
    "plt.quiver(X,Y,U_c,V_c,color='red')\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741cad3a",
   "metadata": {},
   "source": [
    "We obained an error of the order of 9.5 % with respect to the clean signal. Judging from the quiver plot, it is not too bad. We should consider that the velocity is very low in most of the domain so a small absolute error produce a large relative error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1586cf17",
   "metadata": {},
   "source": [
    "## Approach 2: Penalized regression of a vector field\n",
    "\n",
    "We use one SPICY object and proceed with the regression of a vector field. We include penalties on the divergence free condition. We create the object and clone the cluster data. Then proceed from there onward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76646b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "SP_vec = spicy([U_noise,V_noise], [X,Y], basis='c4') # create SPICY object\n",
    "# clone the cluster data:\n",
    "SP_vec.r_mM=SP_V.r_mM; SP_vec.eps_l=SP_V.eps_l;     \n",
    "SP_vec.X_C=SP_V.X_C; SP_vec.Y_C=SP_V.Y_C;     \n",
    "SP_vec.c_k=SP_V.c_k; SP_vec.d_k=SP_V.d_k;     \n",
    "# Proceed as usual: constraints + assembly regression + solve \n",
    "SP_vec.vector_constraints() #add no constraints!\n",
    "SP_vec.Assembly_Regression(alpha_div=1) # assembly with a penalty of 1 on div\n",
    "SP_vec.Solve(K_cond=1e8) # Solve as usual\n",
    "# Get the results on the same grid:\n",
    "U_c,V_c=SP_vec.Get_Sol([X,Y])\n",
    "     \n",
    "error = np.linalg.norm(U_c - U) / np.linalg.norm(U)\n",
    "print('l2 relative error in u component: {0:.3f}%'.format(error*100))\n",
    "error = np.linalg.norm(V_c - V) / np.linalg.norm(V)\n",
    "print('l2 relative error in v component: {0:.3f}%'.format(error*100))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e512575f",
   "metadata": {},
   "source": [
    "The penalty helps reducing slightly the error ! But the main advantage is not there. We can look at the derivatives. More specifically, we can plot the field divergence (which should be zero ideally) for the two cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa1f1f4",
   "metadata": {},
   "source": [
    "#### Divergence Check\n",
    "\n",
    "We check the divergence of the computed fields on a new grid (points not used in the training). We can use 'Get_first_Derivatives' for both the scalar and the vector SPICY objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffd6890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We look for derivatives in a new grid.\n",
    "Xg, Yg = np.meshgrid(np.linspace(-0.5,0.5,100), \n",
    "                     np.linspace(-0.5,0.5,100))\n",
    "\n",
    "\n",
    "# Derivative calculations for the unconstrained case\n",
    "dudx,_=SP_U.Get_first_Derivatives([Xg.reshape(-1),\n",
    "                                  Yg.reshape(-1)])    \n",
    "\n",
    "_,dvdy=SP_V.Get_first_Derivatives([Xg.reshape(-1),\n",
    "                                  Yg.reshape(-1)])    \n",
    "\n",
    "DIV=dudx+dvdy\n",
    "\n",
    "\n",
    "# Derivative calculations for penalized case\n",
    "dudx_p,_,_,dvdy_p=SP_vec.Get_first_Derivatives([Xg.reshape(-1),\n",
    "                                  Yg.reshape(-1)])    \n",
    "DIV_p=dudx_p+dvdy_p\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(15,5), dpi=100)\n",
    "axes[0].set_title('Free Case')\n",
    "sc=axes[0].scatter(Xg, Yg, c=DIV)\n",
    "plt.colorbar(sc,ax=axes[0])\n",
    "axes[1].set_title('Penalized Case')\n",
    "sc2=axes[1].scatter(Xg, Yg, c=DIV_p)\n",
    "plt.colorbar(sc2,ax=axes[1])\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_aspect(1)\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2b0135",
   "metadata": {},
   "source": [
    "Clearly the overal divergence is reduced in the second case thanks to the penalty term!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10566b53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
